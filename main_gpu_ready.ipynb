{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c01403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== GPU SETUP CELL (Added) ====\n",
    "import os, torch\n",
    "\n",
    "# optional: restrict visible GPU(s)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# enforce CUDA\n",
    "assert torch.cuda.is_available(), \"❌ CUDA not available. Please check your GPU setup.\"\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print(\"✅ Using device:\", device)\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# cuDNN speedup settings\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d6fd6b",
   "metadata": {},
   "source": [
    "import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13524881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import colorama\n",
    "from colorama import Fore, Style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc453f73",
   "metadata": {},
   "source": [
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf40b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Root_dir = \"D:/DhanshreeandTeamAI/Github/plant_disease_detection/dataset/New Plant Diseases Dataset(Augmented)\"\n",
    "train_dir = Root_dir + \"/train\"\n",
    "valid_dir = Root_dir + \"/valid\"\n",
    "test_dir = \"D:/DhanshreeandTeamAI/Github/plant_disease_detection/dataset/test\"\n",
    "Diseases_classes = os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c140e94",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a1631a",
   "metadata": {},
   "source": [
    "How many classes in the dataset? \n",
    "\n",
    "Name of classes and Numbr them ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96677694",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Fore.GREEN +str(Diseases_classes))\n",
    "print(\"\\nTotal number of classes are: \", len(Diseases_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92373710",
   "metadata": {},
   "source": [
    "\n",
    "  - How many image are in each classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a76e1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(60,60), dpi=200)\n",
    "cnt = 0\n",
    "plant_names = []\n",
    "tot_images = 0\n",
    "\n",
    "for i in Diseases_classes:\n",
    "    cnt += 1\n",
    "    plant_names.append(i)\n",
    "    plt.subplot(7,7,cnt)\n",
    "    \n",
    "    image_path = os.listdir(train_dir + \"/\" + i)\n",
    "    print(Fore.GREEN)\n",
    "    print(\"The Number of Images in \" +i+ \":\", len(image_path), end= \" \")\n",
    "    tot_images += len(image_path)\n",
    "    \n",
    "    img_show = plt.imread(train_dir + \"/\" + i + \"/\" + image_path[0])\n",
    "    \n",
    "    plt.imshow(img_show)\n",
    "    plt.xlabel(i,fontsize=30)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    \n",
    "print(\"\\nTotal Number of Images in Directory: \", tot_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d874bdf6",
   "metadata": {},
   "source": [
    "Comparing the Number of Classes**\n",
    "\n",
    "  - It's really important to know which classes have the most images and which have the lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdc51cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_names = []\n",
    "Len = []\n",
    "for i in Diseases_classes:\n",
    "    plant_names.append(i)\n",
    "    imgs_path = os.listdir(train_dir + \"/\" + i)\n",
    "    Len.append(len(imgs_path))\n",
    "\n",
    "Len.sort(reverse=True)\n",
    "\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "plt.figure(figsize=(20,20),dpi=200)\n",
    "ax = sns.barplot(x= Len, y= plant_names, palette=\"Greens\")\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c04d09",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "* **ImageFolder/ ToTensor**\n",
    "\n",
    "  - The ImageFolder class in PyTorch, part of the Torchvision library, is a versatile data loader specifically designed for handling image datasets. It simplifies the process of loading and organizing image data for training machine learning models. Let’s delve into its details:\n",
    "Purpose: The ImageFolder class is used to load image data from a directory structure where images are organized into subfolders representing different classes or categories. By default, it assumes the following directory structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3688f888",
   "metadata": {},
   "source": [
    "<div style = 'border : 3px solid non; background-color:#ECFFDC ; ;padding:10px'>\n",
    "\n",
    "    root/\n",
    "    ├── class_1/\n",
    "    │   ├── image1.jpg\n",
    "    │   ├── image2.jpg\n",
    "    │   └── ...\n",
    "    ├── class_2/\n",
    "    │   ├── image3.jpg\n",
    "    │   ├── image4.jpg\n",
    "    │   └── ...\n",
    "    └── ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fd3f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ImageFolder(train_dir, transform=transforms.ToTensor())\n",
    "valid = ImageFolder(valid_dir, transform=transforms.ToTensor()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedaf480",
   "metadata": {},
   "outputs": [],
   "source": [
    "train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feab713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cd5cbd",
   "metadata": {},
   "source": [
    "The last number (0, 1, 2, ...) shows the number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0828a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6a52fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[70000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97e1952",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train[0]\n",
    "print(img.shape, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01085af",
   "metadata": {},
   "source": [
    "3 is the number of channels (RGB) and 256 x 256 is the width and height of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3a328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, label):\n",
    "    print(\"Label :\" + train.classes[label] + \"(\" + str(label) + \")\")\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "    \n",
    "    \n",
    "image_list = [0, 3000, 5000, 8000, 12000, 15000, 60000, 70000]\n",
    "    \n",
    "chs = 0\n",
    "for img in image_list:\n",
    "    chs += 1\n",
    "    plt.subplot(2,4,chs)\n",
    "    print(Fore.GREEN)\n",
    "    plt.tight_layout()\n",
    "    plt.xlabel(img,fontsize=10)\n",
    "    plt.title(train[img][1])\n",
    "    show_image(*train[img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23e7531",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceff22d",
   "metadata": {},
   "source": [
    "**DataLoader:**\n",
    "   - Dataloader is a class for PyTorch data loading utility. It is used to import data from datasets. \n",
    "    \n",
    "   - **Dataloader has two different types of datasets:** map-style datasets and iterable-style datasets. The PyTorch DataLoader class is an important tool to help you prepare, manage, and serve your data to your deep learning networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697de58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders for training and validation\n",
    "train_dataloader = DataLoader(train, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "valid_dataloader = DataLoader(valid, batch_size, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f0c140",
   "metadata": {},
   "source": [
    "### Device of Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b78ac71",
   "metadata": {},
   "source": [
    "**GPU/CPU:** \n",
    "   - When designing your deep learning architecture, your decision to include GPUs relies on several factors:\n",
    "\n",
    "   - Memory bandwidth—including GPUs can provide the bandwidth needed to accommodate large datasets. \n",
    "    \n",
    "   - Dataset size GPUs in parallel can scale more easily than CPUs, enabling you to process massive datasets faster.\n",
    "    \n",
    "   - Optimization a downside of GPUs is that optimization of long-running individual tasks is sometimes more difficult than with CPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb85eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for moving data into GPU (if available)\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available:\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cuda\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7311445",
   "metadata": {},
   "source": [
    "<div style = 'border : 3px solid non; background-color:#ECFFDC ; ;padding:10px'>\n",
    "\n",
    "\n",
    "**Data to Device:** \n",
    "\n",
    "\n",
    "   - In PyTorch, it’s crucial to use .to(device) when you explicitly want to move tensors (data) or entire models (including layers and parameters) to a specific device for computation. **Here’s why:**\n",
    "\n",
    "   - **Consistent Device Placement:**\n",
    "When working with GPUs (Graphics Processing Units), you need to ensure that both the model and the data reside on the same device (either CPU or GPU).\n",
    "If the data is on the CPU and the model is on the GPU (or vice versa), you’ll encounter a runtime error.\n",
    "To avoid this, use .to(device) to transfer both the data and the model to the same device.\n",
    "    \n",
    "   - **Avoiding Mixed Device Operations:**\n",
    "If an operation involves one tensor on the GPU and another on the CPU, PyTorch will raise a Runtime Error.\n",
    "For example, attempting to perform operations between tensors on different devices will result in an error like: “Expected object of device type cuda but got device type cpu.”\n",
    "    \n",
    "   - **Setting the Device:**\n",
    "You can set a variable device to 'cuda' if a GPU is available, otherwise set it to 'cpu'.\n",
    "Then, move both the model and the data to the specified device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb73640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for moving data to device (CPU or GPU)\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db9ac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading in the device (GPU if available else CPU)\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dataloader, device):\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dataloader:\n",
    "            yield to_device(b, self.device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a453ecbc",
   "metadata": {},
   "source": [
    "- CUDA is a programming model and computing toolkit developed by NVIDIA. It enables you to perform compute-intensive operations faster by parallelizing tasks across GPUs. CUDA is the dominant API used for deep learning although other options are available, such as OpenCL. PyTorch provides support for CUDA in the torch.cuda library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94923d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving data into GPU, WrappedDataLoader\n",
    "train_dataloader = DeviceDataLoader(train_dataloader, device)\n",
    "valid_dataloader = DeviceDataLoader(valid_dataloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85715f00",
   "metadata": {},
   "source": [
    "### CNN(Convolutional Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacf97d3",
   "metadata": {},
   "source": [
    "\n",
    "**Function of Acc:** \n",
    "\n",
    "\n",
    "   - We can compare the outputs of model with the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de966f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for calculating the accuracy\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa909ee2",
   "metadata": {},
   "source": [
    "**Classification Base:** \n",
    "\n",
    "\n",
    "   - Let's create a step by step classification base module:\n",
    "    \n",
    "   - **First, Training_step:** the images and labels take values from batch. The output of model is a type of images and the loss is calculate from **F** cross entropy function (out, labels). It seems that the prediction is compared with the actual values in labels.\n",
    "    \n",
    "   - **Second, validation step:** is just like the above one. But it has another attribute call acc.\n",
    "    \n",
    "   - **Third, validation_epoch_end:** calculate the losses and acces of each batchs and epochs.\n",
    "    \n",
    "   - **Fourth, epoch_end:** That shows the final results of everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e102fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222f2e9d",
   "metadata": {},
   "source": [
    "**ConvBlock:** \n",
    "\n",
    "\n",
    "   - Number of inputs, outputs, kernel size and padding are here.\n",
    "    \n",
    "   - Also we have Batchnomalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2975bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution block with BatchNormalization\n",
    "def ConvBlock(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "             nn.BatchNorm2d(out_channels),\n",
    "             nn.ReLU(inplace=True)]\n",
    "    if pool:\n",
    "        layers.append(nn.MaxPool2d(4))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5354cef",
   "metadata": {},
   "source": [
    "**CNN:** \n",
    "\n",
    "\n",
    "   - And the CNN part\n",
    "    \n",
    "   - We can use the class of **ImageClassificationBase** for taking methods like calculating the loss and acc of epochs. And after that, we can set our layers. We can use more layers but in this case, the size of images don't allow to do that **Going to be zero**. In the second part, we have to connect layers to each other. The output of layer number **N**, is the input of layer number **N+1**. And so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feb5b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet architecture \n",
    "class CNN_NeuralNet(ImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_diseases):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = ConvBlock(in_channels, 64)\n",
    "        self.conv2 = ConvBlock(64, 128, pool=True) \n",
    "        self.res1 = nn.Sequential(ConvBlock(128, 128), ConvBlock(128, 128))\n",
    "        \n",
    "        self.conv3 = ConvBlock(128, 256, pool=True) \n",
    "        self.conv4 = ConvBlock(256, 512, pool=True)\n",
    "        #self.conv5 = ConvBlock(256, 256, pool=True)\n",
    "        #self.conv6 = ConvBlock(256, 512, pool=True)\n",
    "        #self.conv7 = ConvBlock(512, 512, pool=True)\n",
    "        \n",
    "        self.res2 = nn.Sequential(ConvBlock(512, 512), ConvBlock(512, 512))\n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n",
    "                                       nn.Flatten(),\n",
    "                                       nn.Linear(512, num_diseases))\n",
    "        \n",
    "    def forward(self, x): # x is the loaded batch\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        #out = self.conv5(out)\n",
    "        #out = self.conv6(out)\n",
    "        #out = self.conv7(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2329bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd869d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245c8567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test CUDA first:\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe6cb1c",
   "metadata": {},
   "source": [
    "#### Model:\n",
    "\n",
    "\n",
    "   - Now it's time to connet the model to_device for using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a53c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # defining the model and moving it to the GPU\n",
    "# 3 is number of channels RGB, len(train.classes()) is number of diseases.\n",
    "model = to_device(CNN_NeuralNet(3, len(train.classes)), device) \n",
    "model\n",
    " \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "# Check and activate GPU\n",
    "device = torch.device(\"cuda\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU not available, using CPU\")\n",
    "\n",
    "# defining the model and moving it to GPU\n",
    "# 3 is number of channels RGB, len(train.classes()) is number of diseases.\n",
    "model = to_device(CNN_NeuralNet(3, len(train.classes)), device) \n",
    "model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697e604e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GPU activation\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Current device: {next(model.parameters()).device}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
